{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using data from \n",
    "https://github.com/sebastianpinedaar/finetuning_text_classifiers/blob/main/\n",
    "\n",
    "\n",
    "### USE FTC KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(os.getcwd())\nsys.path.append(os.getcwd()+ '/finetuning_text_classifiers')\n\nfrom metadataset.ftc.metadataset import FTCMetadataset"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset                                  Split    Mini     FTC     \n",
      "--------------------------------------------------------------------\n",
      "imdb                                     valid    5000     5000    \n",
      "imdb                                     test     25000    25000   \n",
      "mteb/tweet_sentiment_extraction          valid    5497     5497    \n",
      "mteb/tweet_sentiment_extraction          test     3534     3534    \n",
      "ag_news                                  valid    24000    24000   \n",
      "ag_news                                  test     7600     7600    \n",
      "dbpedia_14                               valid    112000   112000  \n",
      "dbpedia_14                               test     70000    70000   \n",
      "stanfordnlp/sst2                         valid    13470    13470   \n",
      "stanfordnlp/sst2                         test     10776    10776   \n",
      "SetFit/mnli                              valid    78541    78541   \n",
      "SetFit/mnli                              test     62833    62833   \n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data\"\n",
    "ftc = FTCMetadataset(data_dir=str(data_dir),\n",
    "                       metric_name=\"error\",\n",
    "                       data_version=\"extended\")\n",
    "mini = FTCMetadataset(data_dir=str(data_dir),\n",
    "                        metric_name=\"error\",\n",
    "                        data_version=\"mini\")\n",
    "\n",
    "splits = ['valid', 'test']\n",
    "dataset_names = mini.get_dataset_names()\n",
    "\n",
    "print(f\"{'Dataset':<40} {'Split':<8} {'Mini':<8} {'FTC':<8}\")\n",
    "print(\"-\" * 68)\n",
    "\n",
    "for name in dataset_names:\n",
    "    for split in splits:\n",
    "        mini.set_state(name, split)\n",
    "        mini_samples = len(mini.get_targets())\n",
    "\n",
    "        ftc.set_state(name, split)\n",
    "        ftc_samples = len(ftc.get_targets())\n",
    "\n",
    "        print(f\"{name:<40} {split:<8} {mini_samples:<8} {ftc_samples:<8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset                                  Split    Type     Ensemble Members   Classes    Samples   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "imdb                                     valid    mini     125                2          5000      \n",
      "imdb                                     valid    ftc      125                2          5000      \n",
      "imdb                                     test     mini     125                2          25000     \n",
      "imdb                                     test     ftc      125                2          25000     \n",
      "mteb/tweet_sentiment_extraction          valid    mini     100                3          5497      \n",
      "mteb/tweet_sentiment_extraction          valid    ftc      100                3          5497      \n",
      "mteb/tweet_sentiment_extraction          test     mini     100                3          3534      \n",
      "mteb/tweet_sentiment_extraction          test     ftc      100                3          3534      \n",
      "ag_news                                  valid    mini     120                4          24000     \n",
      "ag_news                                  valid    ftc      99                 4          24000     \n",
      "ag_news                                  test     mini     120                4          7600      \n",
      "ag_news                                  test     ftc      99                 4          7600      \n",
      "dbpedia_14                               valid    mini     65                 14         112000    \n",
      "dbpedia_14                               valid    ftc      25                 14         112000    \n",
      "dbpedia_14                               test     mini     65                 14         70000     \n",
      "dbpedia_14                               test     ftc      25                 14         70000     \n",
      "stanfordnlp/sst2                         valid    mini     125                2          13470     \n",
      "stanfordnlp/sst2                         valid    ftc      125                2          13470     \n",
      "stanfordnlp/sst2                         test     mini     125                2          10776     \n",
      "stanfordnlp/sst2                         test     ftc      125                2          10776     \n",
      "SetFit/mnli                              valid    mini     100                3          78541     \n",
      "SetFit/mnli                              valid    ftc      25                 3          78541     \n",
      "SetFit/mnli                              test     mini     100                3          62833     \n",
      "SetFit/mnli                              test     ftc      25                 3          62833     \n"
     ]
    }
   ],
   "source": [
    "ftc = FTCMetadataset(data_dir=str(data_dir),\n",
    "                       metric_name=\"error\",\n",
    "                       data_version=\"extended\")\n",
    "mini = FTCMetadataset(data_dir=str(data_dir),\n",
    "                        metric_name=\"error\",\n",
    "                        data_version=\"mini\")\n",
    "\n",
    "splits = ['valid', 'test']\n",
    "dataset_names = mini.get_dataset_names()\n",
    "\n",
    "# Print header\n",
    "print(f\"{'Dataset':<40} {'Split':<8} {'Type':<8} {'Ensemble Members':<18} {'Classes':<10} {'Samples':<10}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for name in dataset_names:\n",
    "    for split in splits:\n",
    "        # Mini dataset\n",
    "        mini.set_state(name, split)\n",
    "        mini_targets = mini.get_targets()\n",
    "        mini_hp_candidates, mini_indices = mini._get_hp_candidates_and_indices()\n",
    "        mini_predictions = mini.get_predictions([[0]])\n",
    "        mini_num_members = len(mini_indices)\n",
    "        mini_num_classes = mini_predictions.shape[-1]\n",
    "        mini_num_samples = len(mini_targets)\n",
    "\n",
    "        # FTC dataset\n",
    "        ftc.set_state(name, split)\n",
    "        ftc_targets = ftc.get_targets()\n",
    "        ftc_hp_candidates, ftc_indices = ftc._get_hp_candidates_and_indices()\n",
    "        ftc_predictions = ftc.get_predictions([[0]])\n",
    "        ftc_num_members = len(ftc_indices)\n",
    "        ftc_num_classes = ftc_predictions.shape[-1]\n",
    "        ftc_num_samples = len(ftc_targets)\n",
    "\n",
    "        # Print mini row\n",
    "        print(f\"{name:<40} {split:<8} {'mini':<8} {mini_num_members:<18} {mini_num_classes:<10} {mini_num_samples:<10}\")\n",
    "        # Print FTC row\n",
    "        print(f\"{name:<40} {split:<8} {'ftc':<8} {ftc_num_members:<18} {ftc_num_classes:<10} {ftc_num_samples:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset                                  Split    Mini (members, samples, classes)    FTC (members, samples, classes)    \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "imdb                                     valid    torch.Size([125, 5000, 2])          torch.Size([125, 5000, 2])         \n",
      "imdb                                     test     torch.Size([125, 25000, 2])         torch.Size([125, 25000, 2])        \n",
      "mteb/tweet_sentiment_extraction          valid    torch.Size([100, 5497, 3])          torch.Size([100, 5497, 3])         \n",
      "mteb/tweet_sentiment_extraction          test     torch.Size([100, 3534, 3])          torch.Size([100, 3534, 3])         \n",
      "ag_news                                  valid    torch.Size([120, 24000, 4])         torch.Size([99, 24000, 4])         \n",
      "ag_news                                  test     torch.Size([120, 7600, 4])          torch.Size([99, 7600, 4])          \n",
      "dbpedia_14                               valid    torch.Size([65, 112000, 14])        torch.Size([25, 112000, 14])       \n",
      "dbpedia_14                               test     torch.Size([65, 70000, 14])         torch.Size([25, 70000, 14])        \n",
      "stanfordnlp/sst2                         valid    torch.Size([125, 13470, 2])         torch.Size([125, 13470, 2])        \n",
      "stanfordnlp/sst2                         test     torch.Size([125, 10776, 2])         torch.Size([125, 10776, 2])        \n",
      "SetFit/mnli                              valid    torch.Size([100, 78541, 3])         torch.Size([25, 78541, 3])         \n",
      "SetFit/mnli                              test     torch.Size([100, 62833, 3])         torch.Size([25, 62833, 3])         \n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data\"\n",
    "ftc = FTCMetadataset(data_dir=str(data_dir),\n",
    "                       metric_name=\"error\",\n",
    "                       data_version=\"extended\")\n",
    "mini = FTCMetadataset(data_dir=str(data_dir),\n",
    "                        metric_name=\"error\",\n",
    "                        data_version=\"mini\")\n",
    "\n",
    "splits = ['valid', 'test']\n",
    "dataset_names = mini.get_dataset_names()\n",
    "\n",
    "print(f\"{'Dataset':<40} {'Split':<8} {'Mini (members, samples, classes)':<35} {'FTC (members, samples, classes)':<35}\")\n",
    "print(\"-\" * 120)\n",
    "\n",
    "for name in dataset_names:\n",
    "    for split in splits:\n",
    "        # Get all predictions and their shapes\n",
    "        mini.set_state(name, split)\n",
    "        _, mini_indices = mini._get_hp_candidates_and_indices()\n",
    "        mini_shape = mini.get_predictions(mini_indices).shape\n",
    "\n",
    "        ftc.set_state(name, split)\n",
    "        _, ftc_indices = ftc._get_hp_candidates_and_indices()\n",
    "        ftc_shape = ftc.get_predictions(ftc_indices).shape\n",
    "\n",
    "        print(f\"{name:<40} {split:<8} {str(mini_shape):<35} {str(ftc_shape):<35}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "#data_version = \"mini\" #10% of total with 20% val split\n",
    "data_version = \"extended\"                              # NOTE not yet downloaded\n",
    "metadataset = FTCMetadataset(data_dir=str(data_dir), \n",
    "                             metric_name=\"error\",\n",
    "                             data_version=data_version)\n",
    "dataset_names = metadataset.get_dataset_names()\n",
    "dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: imdb num_configs: 125 num_classes: tensor(1) num_val_samples: 5000 num_test_samples: 25000\n",
      "Dataset: mteb/tweet_sentiment_extraction num_configs: 100 num_classes: tensor(2) num_val_samples: 5497 num_test_samples: 3534\n",
      "Dataset: ag_news num_configs: 120 num_classes: tensor(3) num_val_samples: 24000 num_test_samples: 7600\n",
      "Dataset: dbpedia_14 num_configs: 65 num_classes: tensor(13) num_val_samples: 112000 num_test_samples: 70000\n",
      "Dataset: stanfordnlp/sst2 num_configs: 125 num_classes: tensor(1) num_val_samples: 13470 num_test_samples: 10776\n",
      "Dataset: SetFit/mnli num_configs: 100 num_classes: tensor(2) num_val_samples: 78541 num_test_samples: 62833\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in dataset_names:\n",
    "\n",
    "    metadataset.set_state(dataset_name=dataset_name,\n",
    "                        split=\"valid\")\n",
    "    hp_candidates, indices = metadataset._get_hp_candidates_and_indices()\n",
    "    predictions = metadataset.get_predictions([[0]])\n",
    "    targets = metadataset.get_targets()\n",
    "    num_configs = len(hp_candidates)\n",
    "    num_classes = max(targets)\n",
    "    num_val_samples = len(targets)\n",
    "\n",
    "    metadataset.set_state(dataset_name=dataset_name,\n",
    "                        split=\"test\")\n",
    "    targets = metadataset.get_targets()\n",
    "    num_test_samples = len(targets)\n",
    "\n",
    "    print(\"Dataset:\", dataset_name,\n",
    "        \"num_configs:\", num_configs,\n",
    "          \"num_classes:\", num_classes,\n",
    "           \"num_val_samples:\", num_val_samples,\n",
    "           \"num_test_samples:\", num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreive the IMDB dataset\n",
    "\n",
    "- Hyper parameters consist of LORA rank, learning rate and model (GPT2, Bert-Large, Albert-Large, Bart-Large, T5-Large)\n",
    "\n",
    "- Greedy 50 always provide the highest score (NLL)\n",
    "\n",
    "- Target tensor has 0, 1 => binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [  8.  16.  32.  64. 128.]\n",
      "1 [5.e-03 1.e-03 5.e-04 1.e-04 1.e-05]\n",
      "2 [0. 1.]\n",
      "3 [0. 1.]\n",
      "4 [0. 1.]\n",
      "5 [0. 1.]\n",
      "6 [1. 0.]\n",
      "----------------------\n",
      "indices [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124]\n",
      "Shape of hp_candidates: (125, 7)\n",
      "Shape of indices: (125, 1)\n",
      "----------------------\n",
      "Shape of predictions: torch.Size([1, 1, 5000, 2])\n",
      "Shape of targets: torch.Size([5000])\n",
      "Unique values in targets: tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "imdb_name = dataset_names[0]\n",
    "metadataset.set_state(dataset_name=imdb_name,\n",
    "                    split=\"valid\")\n",
    "hp_candidates, indices = metadataset._get_hp_candidates_and_indices()\n",
    "\n",
    "hp_candidates = pd.DataFrame(hp_candidates)\n",
    "indices = pd.DataFrame(indices)\n",
    "indices\n",
    "\n",
    "#understand the data get unique values\n",
    "cols = hp_candidates.columns\n",
    "for col in cols:\n",
    "    print(col, hp_candidates[col].unique())\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "print('indices', indices[0].unique())\n",
    "print('Shape of hp_candidates:', hp_candidates.shape)\n",
    "print('Shape of indices:', indices.shape)\n",
    "\n",
    "print('----------------------')\n",
    "predictions = metadataset.get_predictions([[0]])\n",
    "print('Shape of predictions:', predictions.shape)\n",
    "\n",
    "targets = metadataset.get_targets()\n",
    "print('Shape of targets:', targets.shape)\n",
    "print('Unique values in targets:', targets.unique())\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions for all candidates: torch.Size([125, 5000, 2])\n"
     ]
    }
   ],
   "source": [
    "all_indices = list(range(hp_candidates.shape[0]))  # hp_candidates.shape[0] should be 125\n",
    "predictions_all = metadataset.get_predictions(all_indices)\n",
    "print(\"Shape of predictions for all candidates:\", predictions_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadataset.set_state(dataset_name=imdb_name,\n",
    "                    split=\"test\")\n",
    "hp_candidates_test, indices_test = metadataset._get_hp_candidates_and_indices()\n",
    "metadataset.set_state(dataset_name=imdb_name,\n",
    "                    split=\"valid\")\n",
    "hp_candidates_valid, indices_valid = metadataset._get_hp_candidates_and_indices()\n",
    "(hp_candidates_test !=  hp_candidates_valid).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess to get all ensemble probabilites for all models across validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds:  torch.Size([125, 5000, 2]) Targets:  torch.Size([5000])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "def retrieve_data(dataset_name, splits):\n",
    "    \"\"\"\n",
    "       hp_candidates, indices, predictions, targets \n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for split in splits:\n",
    "        metadataset.set_state(dataset_name=dataset_name,\n",
    "                        split=split)\n",
    "        hp_candidates, indices = metadataset._get_hp_candidates_and_indices()\n",
    "        predictions = metadataset.get_predictions(indices)\n",
    "        targets = metadataset.get_targets()\n",
    "        results[split] = (hp_candidates, indices, predictions, targets)\n",
    "    return results\n",
    "\n",
    "splits = [\"valid\", \"test\"]\n",
    "imdb_name = dataset_names[0]\n",
    "results = retrieve_data(imdb_name, splits)\n",
    "\n",
    "\n",
    "# lets have a look at the data\n",
    "print('Preds: ',results['valid'][2].shape, 'Targets: ', results['valid'][3].shape)\n",
    "# Sanity check\n",
    "print((results['valid'][1] != results['test'][1]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparision with the paper\n",
    "\n",
    "### Starting with looking at a greedy implementation\n",
    "\n",
    "1. Best\n",
    "2. Greedy 5\n",
    "3. Greedy 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble members [124]: NLL = 0.2141\n",
      "torch.Size([1, 25000, 2]) torch.Size([25000])\n",
      "Non claibrated nll : 0.2085971087217331\n",
      "Ensemble members [124, 98, 118, 84, 87]: NLL = 0.1305\n",
      "torch.Size([5, 25000, 2]) torch.Size([25000])\n",
      "Non claibrated nll : 0.12724649906158447\n",
      "Ensemble members [124, 98, 118, 84, 87, 43, 113, 112, 82, 93, 117, 109, 108, 94, 54, 83, 97, 103, 99, 114, 7, 123, 77, 38, 79, 102, 88, 107, 73, 78, 11, 92, 89, 68, 122, 119, 28, 53, 69, 63, 48, 58, 104, 8, 64, 22, 59, 33, 12, 2]: NLL = 0.1325\n",
      "torch.Size([50, 25000, 2]) torch.Size([25000])\n",
      "Non claibrated nll : 0.13053670525550842\n"
     ]
    }
   ],
   "source": [
    "def greedy_select_ensemble(member_probs, labels, m, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        member_probs shape [num_members, num_samples, num_classes] \n",
    "        labels shape [num_samples] \n",
    "    Returns:\n",
    "        selected (list of int): The indices (with respect to member_probs) of the selected ensemble members.\n",
    "        ensemble_nlls (list of float): The ensemble NLL after each member is added.\n",
    "    \"\"\"\n",
    "    # Ensure labels is a tensor.\n",
    "    if not torch.is_tensor(member_probs) and torch.is_tensor(labels):\n",
    "        raise ValueError('Invalid data type as input')\n",
    "\n",
    "    \n",
    "    num_members = member_probs.shape[0]\n",
    "    \n",
    "    # Function to compute ensemble NLL given a list of candidate indices.\n",
    "    def compute_ensemble_nll(indices, member_probs, labels, epsilon):\n",
    "        ensemble_probs = member_probs[indices].mean(dim=0)\n",
    "        nll = -torch.gather(torch.log(ensemble_probs + epsilon), dim = 1, index = labels.unsqueeze(1)).squeeze()\n",
    "        nll_mean = nll.mean()\n",
    "        return nll_mean.item()\n",
    "    \n",
    "    selected = []       # List to hold the indices of selected members.\n",
    "    ensemble_nlls = []  # List to hold the ensemble NLL after each addition.\n",
    "    \n",
    "    # Create a set of all candidate indices.\n",
    "    remaining = set(range(num_members))\n",
    "    \n",
    "    # Greedy forward selection:\n",
    "    for i in range(m):\n",
    "        best_candidate = None\n",
    "        best_nll = float('inf')\n",
    "        \n",
    "        # Evaluate each candidate in the remaining pool.\n",
    "        for candidate in remaining:\n",
    "            candidate_set = selected + [candidate]\n",
    "            candidate_nll = compute_ensemble_nll(candidate_set, member_probs, labels, eps)\n",
    "            if candidate_nll < best_nll:\n",
    "                best_nll = candidate_nll\n",
    "                best_candidate = candidate\n",
    "        \n",
    "        # Add the best candidate for this iteration.\n",
    "        selected.append(best_candidate)\n",
    "        remaining.remove(best_candidate)\n",
    "        ensemble_nlls.append(best_nll)\n",
    "        if i == (m-1):\n",
    "            print(f\"Ensemble members {selected}: NLL = {best_nll:.4f}\")\n",
    "    \n",
    "    return selected, ensemble_nlls\n",
    "\n",
    "# Example usage:\n",
    "def compute_ensemble_nll(member_probs, labels, eps=1e-12):\n",
    "    ensemble_probs = member_probs.mean(dim=0)  # [num_samples, num_classes]\n",
    "    nll = -torch.gather(torch.log(ensemble_probs + eps), 1, labels.unsqueeze(1)).squeeze(1)\n",
    "    return nll.mean().item()\n",
    "\n",
    "member_probs = results['valid'][2]\n",
    "labels = results['valid'][3]\n",
    "\n",
    "for m in [1, 5, 50]:\n",
    "    indices, losses = greedy_select_ensemble(member_probs, labels, m)\n",
    "\n",
    "    temp_test_probs = results['test'][2][indices]\n",
    "    temp_test_labels = results['test'][3]\n",
    "    print(temp_test_probs.shape, temp_test_labels.shape)\n",
    "    print(\"Non claibrated nll :\", compute_ensemble_nll(temp_test_probs, temp_test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple best n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124]\n",
      "torch.Size([1, 25000, 2]) torch.Size([25000])\n",
      "Non claibrated nll : 0.2085971087217331\n",
      "[124, 109, 99, 94, 114]\n",
      "torch.Size([5, 25000, 2]) torch.Size([25000])\n",
      "Non claibrated nll : 0.15763503313064575\n",
      "[124, 109, 99, 94, 114, 84, 89, 119, 93, 104, 98, 123, 88, 83, 79, 118, 78, 113, 108, 103, 69, 64, 74, 44, 87, 112, 117, 77, 97, 43, 59, 34, 82, 49, 73, 39, 92, 48, 107, 122, 38, 29, 53, 63, 68, 102, 58, 23, 28, 33]\n",
      "torch.Size([50, 25000, 2]) torch.Size([25000])\n",
      "Non claibrated nll : 0.13196343183517456\n"
     ]
    }
   ],
   "source": [
    "def best_n_ensemble(member_probs, labels, m, eps=1e-12):\n",
    "    num_members = member_probs.shape[0]\n",
    "\n",
    "    individual_nlls = []\n",
    "    for i in range(num_members):\n",
    "        probs = member_probs[i]  # [num_samples, num_classes]\n",
    "        nll = -torch.gather(torch.log(probs + eps), 1, labels.unsqueeze(1)).squeeze(1)\n",
    "        individual_nlls.append(nll.mean().item())\n",
    "\n",
    "    sorted_indices = sorted(range(num_members), key=lambda i: individual_nlls[i])\n",
    "    indices = sorted_indices[:m]\n",
    "    print(indices)\n",
    "    return indices\n",
    "\n",
    "for i in [1, 5, 50]:\n",
    "    ensemble_indices = best_n_ensemble(member_probs, labels, i)\n",
    "    temp_test_probs = results['test'][2][ensemble_indices]\n",
    "    temp_test_labels = results['test'][3]\n",
    "    print(temp_test_probs.shape, temp_test_labels.shape)\n",
    "    print(\"Non claibrated nll :\", compute_ensemble_nll(temp_test_probs, temp_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation based of email from author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 25000, 2]) torch.Size([25000])\n",
      "Non claibrated nll : 0.2085971087217331\n",
      "torch.Size([5, 25000, 2]) torch.Size([25000])\n",
      "Non claibrated nll : 0.12724649906158447\n",
      "torch.Size([50, 25000, 2]) torch.Size([25000])\n",
      "Non claibrated nll : 0.12414136528968811\n"
     ]
    }
   ],
   "source": [
    "def greedy_select_ensemble_with_metric(member_probs, labels, m, metric_name=\"nll\", no_resample=True, eps=1e-12 ):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        member_probs shape [num_members, num_samples, num_classes]\n",
    "        labels shape [num_samples]\n",
    "        m (int): Number of ensemble members to select.\n",
    "        metric_name (str): The metric to use for evaluating the ensemble.\n",
    "        no_resample (bool): If True, do not resample the selected members.\n",
    "        eps (float): Small value to avoid log(0).\n",
    "        \n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(member_probs) and torch.is_tensor(labels):\n",
    "        raise ValueError('Invalid data type as input')\n",
    "    \n",
    "    num_members = member_probs.shape[0]\n",
    "    selected = []       # List to hold the indices of selected models.\n",
    "    remaining = set(range(num_members))\n",
    "    ensemble_metrics = []  # To record the metric after each addition.\n",
    "    \n",
    "    def compute_metric(indices):\n",
    "        # Average the probabilities of the models in 'indices'\n",
    "        ensemble_probs = member_probs[list(indices)].mean(dim=0)  # Shape: [num_samples, num_classes]\n",
    "        if metric_name == \"nll\":\n",
    "            # Negative log-likelihood.\n",
    "            nll = -torch.gather(torch.log(ensemble_probs + eps), 1, labels.unsqueeze(1)).squeeze(1)\n",
    "            return nll.mean().item()\n",
    "        elif metric_name == \"error\":\n",
    "            # Classification error rate.\n",
    "            preds = ensemble_probs.argmax(dim=1)\n",
    "            error_rate = (preds != labels).float().mean().item()\n",
    "            return error_rate\n",
    "        elif metric_name == \"relative_absolute_error\":\n",
    "            # Relative absolute error: |pred - true|/clamp(|true|,min=1)\n",
    "            preds = ensemble_probs.argmax(dim=1).float()\n",
    "            rel_abs_error = (torch.abs(preds - labels) / torch.clamp(torch.abs(labels), min=1.0)).mean().item()\n",
    "            return rel_abs_error\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric_name: {metric_name}\")\n",
    "    \n",
    "    # Greedy forward selection: add one candidate at each iteration.\n",
    "    for i in range(m):\n",
    "        best_candidate = None\n",
    "        best_metric_value = float('inf')\n",
    "        # Evaluate each candidate in the remaining set.\n",
    "        for candidate in remaining:\n",
    "            candidate_set = selected + [candidate]\n",
    "            candidate_metric = compute_metric(candidate_set)\n",
    "            if candidate_metric < best_metric_value:\n",
    "                best_metric_value = candidate_metric\n",
    "                best_candidate = candidate\n",
    "        # Add the best candidate\n",
    "        selected.append(best_candidate)\n",
    "        # If no resampling, remove it from the pool.\n",
    "        if no_resample:\n",
    "            remaining.remove(best_candidate)\n",
    "        ensemble_metrics.append(best_metric_value)\n",
    "        #print(f\"Step {i+1}: Selected ensemble members {selected} => {metric_name} = {best_metric_value:.4f}\")\n",
    "    \n",
    "    return selected, ensemble_metrics\n",
    "\n",
    "\n",
    "member_probs = results['valid'][2]\n",
    "labels = results['valid'][3]\n",
    "\n",
    "for i in [1, 5, 50]:\n",
    "    ensemble_indices, _ = greedy_select_ensemble_with_metric( member_probs, labels, m=i, metric_name=\"nll\", \n",
    "                                                                     no_resample=False)\n",
    "    temp_test_probs = results['test'][2][ensemble_indices]\n",
    "    temp_test_labels = results['test'][3]\n",
    "    print(temp_test_probs.shape, temp_test_labels.shape)\n",
    "    print(\"Non claibrated nll :\", compute_ensemble_nll(temp_test_probs, temp_test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy as by Caruana, R., Niculescu-Mizil, A., Crew, G., and Ksikes, A. \n",
    "\n",
    "Below is the interpretation based on the limited information from their paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual NLLs: [0.45, 0.23, 0.5, 0.31, 0.29]\n",
      "Sorted indices: [1, 4, 3, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "# Suppose we have 5 models and their individual NLL values:\n",
    "individual_nlls = [0.45, 0.23, 0.50, 0.31, 0.29]\n",
    "num_members = len(individual_nlls)  # 5\n",
    "\n",
    "# Create a list of indices [0, 1, 2, 3, 4]\n",
    "all_indices = range(num_members)\n",
    "\n",
    "# Sort these indices by looking up the NLL in individual_nlls\n",
    "# The default sort order is ascending, so the model with the smallest NLL is first.\n",
    "sorted_indices = sorted(range(num_members), key=lambda i: individual_nlls[i], reverse = False)\n",
    "\n",
    "print(\"Individual NLLs:\", individual_nlls)\n",
    "print(\"Sorted indices:\", sorted_indices) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial candidate pool (top 1 models): [124]\n",
      "No improvement of NLL - continouing\n",
      "No improvement of NLL - continouing\n",
      "Stopping early.\n",
      "Initial ensemble size 1.0\n",
      "Final selected ensemble indices: [124, 98, 118, 84, 87, 43, 113, 112, 84, 82, 118]\n",
      "Non claibrated nll : 0.12684710323810577\n",
      "Initial candidate pool (top 2 models): [124, 109]\n",
      "No improvement of NLL - continouing\n",
      "No improvement of NLL - continouing\n",
      "Stopping early.\n",
      "Initial ensemble size 2.0\n",
      "Final selected ensemble indices: [124, 109, 83, 118, 87, 84, 43, 113, 112, 82, 84, 118, 93, 117, 54, 87, 118, 98]\n",
      "Non claibrated nll : 0.1262870877981186\n",
      "Initial candidate pool (top 3 models): [124, 109, 99]\n",
      "No improvement of NLL - continouing\n",
      "No improvement of NLL - continouing\n",
      "Stopping early.\n",
      "Initial ensemble size 3.0\n",
      "Final selected ensemble indices: [124, 109, 99, 118, 87, 84, 112, 43, 113, 98, 82, 118, 84, 117, 93, 54, 87, 108]\n",
      "Non claibrated nll : 0.1260664016008377\n",
      "Initial candidate pool (top 4 models): [124, 109, 99, 94]\n",
      "No improvement of NLL - continouing\n",
      "No improvement of NLL - continouing\n",
      "Stopping early.\n",
      "Initial ensemble size 4.0\n",
      "Final selected ensemble indices: [124, 109, 99, 94, 118, 87, 113, 43, 98, 112, 84, 97, 118, 117, 102, 87, 84, 108, 114, 93, 7, 118, 113, 54, 84, 87, 118, 38, 82, 93, 108, 84, 114, 118, 87, 84, 113, 11, 118, 93, 117, 84, 87, 108, 43, 112, 118, 84]\n",
      "Non claibrated nll : 0.12474167346954346\n",
      "Initial candidate pool (top 5 models): [124, 109, 99, 94, 114]\n",
      "No improvement of NLL - continouing\n",
      "No improvement of NLL - continouing\n",
      "Stopping early.\n",
      "Initial ensemble size 5.0\n",
      "Final selected ensemble indices: [124, 109, 99, 94, 114, 118, 87, 113, 43, 83, 112, 84, 118, 82, 117, 93, 87, 84, 108, 54, 118, 7, 98, 113, 84, 87, 38, 118, 93, 108]\n",
      "Non claibrated nll : 0.12488015741109848\n",
      "Initial candidate pool (top 6 models): [124, 109, 99, 94, 114, 84]\n",
      "No improvement of NLL - continouing\n",
      "No improvement of NLL - continouing\n",
      "Stopping early.\n",
      "Initial ensemble size 6.0\n",
      "Final selected ensemble indices: [124, 109, 99, 94, 114, 84, 118, 87, 112, 43, 113, 83, 118, 82, 117, 93, 87, 108, 54, 118, 93, 7, 118, 98, 87, 38, 113, 108, 77]\n",
      "Non claibrated nll : 0.12462187558412552\n",
      "Initial candidate pool (top 7 models): [124, 109, 99, 94, 114, 84, 89]\n",
      "No improvement of NLL - continouing\n",
      "No improvement of NLL - continouing\n",
      "Stopping early.\n",
      "Initial ensemble size 7.0\n",
      "Final selected ensemble indices: [124, 109, 99, 94, 114, 84, 89, 118, 87, 112, 43, 113, 108, 82, 93, 118, 117, 87, 102, 7, 98, 118, 113, 54, 87, 93, 118, 38, 108, 77]\n",
      "Non claibrated nll : 0.1248498409986496\n",
      "Initial candidate pool (top 8 models): [124, 109, 99, 94, 114, 84, 89, 119]\n",
      "No improvement of NLL - continouing\n",
      "No improvement of NLL - continouing\n",
      "Stopping early.\n",
      "Initial ensemble size 8.0\n",
      "Final selected ensemble indices: [124, 109, 99, 94, 114, 84, 89, 119, 118, 87, 113, 112, 43, 108, 82, 118, 93, 87, 117, 118, 98, 102, 97, 113, 7, 118, 87, 93, 38, 108, 54, 118, 93, 87, 113, 77, 118, 98, 117, 11, 108, 112, 83, 43, 118, 87, 93]\n",
      "Non claibrated nll : 0.12419130653142929\n",
      "Initial candidate pool (top 9 models): [124, 109, 99, 94, 114, 84, 89, 119, 93]\n",
      "No improvement of NLL - continouing\n",
      "No improvement of NLL - continouing\n",
      "Stopping early.\n",
      "Initial ensemble size 9.0\n",
      "Final selected ensemble indices: [124, 109, 99, 94, 114, 84, 89, 119, 93, 118, 87, 112, 43, 108, 118, 82, 113, 87, 117, 118, 98, 102, 97, 113, 7, 118, 87, 108, 38, 54, 83, 118, 77, 113, 98, 87, 118, 112]\n",
      "Non claibrated nll : 0.12399544566869736\n",
      "Initial candidate pool (top 10 models): [124, 109, 99, 94, 114, 84, 89, 119, 93, 104]\n",
      "Initial ensemble size 10.0\n",
      "Final selected ensemble indices: [124, 109, 99, 94, 114, 84, 89, 119, 93, 104, 118, 87, 112, 118, 43, 108, 87, 113, 82, 117, 118, 83, 102, 113, 7, 98, 87, 118, 38, 118, 77, 54, 108, 98, 87, 113, 118, 97, 117, 112, 43, 98, 118, 87, 11, 113, 79, 108, 82, 118]\n",
      "Non claibrated nll : 0.12409476190805435\n"
     ]
    }
   ],
   "source": [
    "def greedy_select_ensemble_with_initial(member_probs, labels, m, init_N, no_resample = True, tolerance = 3, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Greedily selects an ensemble of m models using an initial candidate pool of the best init_N models.\n",
    "    Only adds a candidate if it reduces the ensemble's NLL.\"\n",
    "\n",
    "    Args:\n",
    "        m: Attempted ensemble size\n",
    "        init_N: Number of initial ensemble\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # ------ Helper fn for the ensemble NLL ------\n",
    "    def compute_ensemble_nll(indices):\n",
    "        ensemble_probs = member_probs[indices].mean(dim=0)  # [num_samples, num_classes]\n",
    "        nll = -torch.gather(torch.log(ensemble_probs + eps), 1, labels.unsqueeze(1)).squeeze(1)\n",
    "        return nll.mean().item()\n",
    "    \n",
    "    #ensure m >= init_N\n",
    "    if init_N > m:\n",
    "        raise ValueError('Initial ensemble must be smaller than m')\n",
    "\n",
    "    # Ensure data are tensor.\n",
    "    if not (torch.is_tensor(member_probs) and torch.is_tensor(labels)):\n",
    "        raise ValueError('member_probs and labels must both be tensors')\n",
    "\n",
    "    \n",
    "    num_members = member_probs.shape[0]\n",
    "\n",
    "    # 1. Get the individual nll\n",
    "    individual_nlls = []\n",
    "    for i in range(num_members):\n",
    "        probs = member_probs[i]  # [num_samples, num_classes]\n",
    "        nll = -torch.gather(torch.log(probs + eps), 1, labels.unsqueeze(1)).squeeze(1)\n",
    "        individual_nlls.append(nll.mean().item())\n",
    "    \n",
    "    # 2. Sort models by individual NLL (lower is better).\n",
    "    sorted_indices = sorted(range(num_members), key=lambda i: individual_nlls[i])\n",
    "    \n",
    "    # 3. Form the initial candidate pool (the top init_N models).\n",
    "    init_N = min(init_N, num_members)\n",
    "    candidate_pool = sorted_indices[:init_N] # best init_N members\n",
    "    print(f\"Initial candidate pool (top {init_N} models): {candidate_pool}\")\n",
    "    \n",
    "    # 4. Initialize the ensemble with the full candidate pool.\n",
    "    selected = candidate_pool.copy()\n",
    "    # Based of indices\n",
    "    remaining = set(range(num_members)) - set(candidate_pool)\n",
    "    current_nll = compute_ensemble_nll(selected)\n",
    "    ensemble_nlls = [current_nll]\n",
    "    \n",
    "    # 5. Greedy forward selection: add candidates only if they improve (i.e. lower) the NLL.\n",
    "    counter = 0\n",
    "    while len(selected) < m:\n",
    "        best_candidate = None\n",
    "        best_nll = float('inf')\n",
    "        for candidate in remaining:\n",
    "            candidate_set = selected + [candidate]\n",
    "            candidate_nll = compute_ensemble_nll(candidate_set)\n",
    "            if candidate_nll < best_nll:\n",
    "                best_nll = candidate_nll\n",
    "                best_candidate = candidate\n",
    "        if best_nll < current_nll:\n",
    "            selected.append(best_candidate)\n",
    "            if no_resample:\n",
    "                remaining.remove(best_candidate)\n",
    "            ensemble_nlls.append(best_nll)\n",
    "            current_nll = best_nll\n",
    "            #print(f\"Added candidate {best_candidate}, ensemble {selected}: NLL = {best_nll:.4f}\")\n",
    "            #reset counter\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= tolerance:\n",
    "                print(\"Stopping early.\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"No improvement of NLL - continouing\")\n",
    "\n",
    "    return selected, ensemble_nlls\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "member_probs = results['valid'][2]\n",
    "labels = results['valid'][3]\n",
    "\n",
    "m = 50\n",
    "for i in np.linspace(1,10, 10):\n",
    "    init_N = int(i)    \n",
    "    selected_indices, ensemble_nlls = greedy_select_ensemble_with_initial(member_probs, labels, m, init_N,\n",
    "                                                                          no_resample=False)\n",
    "    print(f\"Initial ensemble size {i}\")\n",
    "    print(\"Final selected ensemble indices:\", selected_indices)\n",
    "\n",
    "    temp_test_probs = results['test'][2][selected_indices]\n",
    "    temp_test_labels = results['test'][3]\n",
    "    print(\"Non claibrated nll :\", compute_ensemble_nll(temp_test_probs, temp_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new greedy 50 function that aims to perform well with calibration \n",
    "\n",
    "**Version A**\n",
    "1. c_1-temperature-calibrate each ensemble candidate\n",
    "2. sort the c_1-temperature-calibrated models by their NLL performance and pick the top 5(?) as an initial ensemble\n",
    "3. for in in range(50):\n",
    "4. calibrate c_1 and c_2 for the ensemble\n",
    "5. add the model that improves the calibrated ensemble NNL the most (without changing c_1 and c_2 to safe computational time)\n",
    "6. calibrate c_1 and c_2 for the ensemble\n",
    "7. return ensemble\n",
    "\n",
    "**Version B**\n",
    "\n",
    "1. c_1-temperature-calibrate each ensemble candidate\n",
    "2. sort the c_1-temperature-calibrated models by their NLL performance and pick the top 5(?) as an initial ensemble\n",
    "3. for in in range(50):\n",
    "4. add the model that improves the calibrated ensemble NNL the most where we recalibrate c_1 and c_2 for each of the 125 candidate ensembles (maybe only use a small grid locally around the winning c_1 and c_2 of the ensemble winning the previous iteration to safe computational time)\n",
    "5. calibrate c_1 and c_2 for the ensemble on a large very fine grid\n",
    "6. return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "\n",
    "Starting with an initial ensemble and then allowing resampling - beats results from the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb',\n",
       " 'mteb/tweet_sentiment_extraction',\n",
       " 'ag_news',\n",
       " 'dbpedia_14',\n",
       " 'stanfordnlp/sst2',\n",
       " 'SetFit/mnli']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('../../src')\n",
    "sys.path.append(os.getcwd()+ '/finetuning_text_classifiers')\n",
    "\n",
    "from calibrator import PrecomputedCalibrator\n",
    "from metadataset.ftc.metadataset import FTCMetadataset\n",
    "\n",
    "data_dir = \"../data\"\n",
    "data_version = \"mini\" #10% of total with 20% val split\n",
    "#data_version = \"extended\"                              # NOTE not yet downloaded\n",
    "metadataset = FTCMetadataset(data_dir=str(data_dir), \n",
    "                             metric_name=\"error\",\n",
    "                             data_version=data_version)\n",
    "dataset_names = metadataset.get_dataset_names()\n",
    "dataset_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: imdb\n",
      "Greedy ensemble completed; selected [124, 98, 118, 84, 87, 43, 113, 112, 84, 82, 118, 109, 93, 117, 54, 87, 108, 84, 124, 118, 97, 113, 84, 7, 87, 118, 38, 93, 108, 124, 84, 118, 87, 84, 102, 113, 11, 118, 93, 117, 84, 87, 112, 114, 83, 118, 43, 82, 84, 113] with NLL = 0.12283\n",
      "Greedy enemble with initial 6; selected [94, 99, 84, 93, 98, 89, 124, 118, 43, 87, 112, 113, 124, 118, 82, 117, 87, 108, 54, 118, 97, 113, 109, 7, 87, 118, 38, 108, 83, 114, 118, 77, 113, 102, 87] with NLL = 0.12412\n",
      "Greedy enemble with temp scaling; selected [94, 99, 84, 93, 98, 109, 118, 87, 43, 113, 112, 118, 82, 117] with NLL = 0.12526\n",
      "Greedy ensemble completed; selected [124, 98, 118, 84, 87, 43, 113, 112, 84, 82, 118, 109, 93, 117, 54, 87, 108, 84, 124, 118, 97, 113, 84, 7, 87, 118, 38, 93, 108, 124, 84, 118, 87, 84, 102, 113, 11, 118, 93, 117, 84, 87, 112, 114, 83, 118, 43, 82, 84, 113] with NLL = 0.12283\n",
      "Greedy enemble with initial 6; selected [94, 99, 84, 93, 98, 89, 124, 118, 43, 87, 112, 113, 124, 118, 82, 117, 87, 108, 54, 118, 97, 113, 109, 7, 87, 118, 38, 108, 83, 114, 118, 77, 113, 102, 87] with NLL = 0.12412\n",
      "Greedy enemble with temp scaling; selected [94, 99, 84, 93, 98, 118, 108, 123, 48, 113, 108, 88, 118, 87, 103, 108, 97, 123, 88, 73, 118, 79, 113, 108, 87, 112, 123, 88, 102, 79, 108, 97, 118, 43, 113, 108, 123, 79, 82, 88, 103, 87, 112, 108, 78, 123, 97, 118, 79, 73] with NLL = 0.12540\n",
      "Greedy ensemble completed; selected [124, 93, 118, 87, 94, 77, 123, 92, 84, 22, 83, 118, 114, 93, 87, 79, 117, 77, 63, 118, 93, 82, 124, 84, 83, 123, 87, 43, 93, 118, 94, 77, 124, 113, 92, 93, 84, 118, 11, 87, 93, 107, 83, 22, 84, 118, 68, 77, 19, 87] with NLL = 0.12538\n",
      "Greedy enemble with initial 5; selected [94, 99, 93, 98, 84, 124, 87, 118, 77, 92, 22, 123, 63, 114, 118, 83, 87, 117, 77, 79, 118, 82, 124, 83, 123, 87, 122] with NLL = 0.12618\n",
      "Greedy enemble with temp scaling; selected [94, 99, 93, 98, 84, 109, 118, 87, 77, 92, 123, 22, 118, 83, 63, 87, 113] with NLL = 0.12634\n",
      "Greedy ensemble completed; selected [124, 93, 118, 87, 94, 77, 123, 92, 84, 22, 83, 118, 114, 93, 87, 79, 117, 77, 63, 118, 93, 82, 124, 84, 83, 123, 87, 43, 93, 118, 94, 77, 124, 113, 92, 93, 84, 118, 11, 87, 93, 107, 83, 22, 84, 118, 68, 77, 19, 87] with NLL = 0.12538\n",
      "Greedy enemble with initial 5; selected [94, 99, 93, 98, 84, 124, 87, 118, 77, 92, 22, 123, 63, 114, 118, 83, 87, 117, 77, 79, 118, 82, 124, 83, 123, 87, 122] with NLL = 0.12618\n",
      "Greedy enemble with temp scaling; selected [94, 99, 93, 98, 84, 118, 103, 83, 123, 87, 108, 43, 83, 118, 79, 122, 123, 82, 83, 63, 108, 87, 103, 79, 83, 123, 92, 113, 88, 108, 87, 79, 97, 103, 82, 123, 122, 79, 77, 103, 87, 108, 48, 79, 82, 123, 83, 122, 103, 87] with NLL = 0.12626\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>ensemble_type</th>\n",
       "      <th>ensemble_size</th>\n",
       "      <th>non_calibrated_nll</th>\n",
       "      <th>calibrated_nll</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>epi_scalar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imdb</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>0.124141</td>\n",
       "      <td>0.124230</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imdb</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy_init</td>\n",
       "      <td>35</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.124087</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imdb</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy_init_temp</td>\n",
       "      <td>14</td>\n",
       "      <td>0.135776</td>\n",
       "      <td>0.125154</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imdb</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>0.124141</td>\n",
       "      <td>0.124155</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imdb</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy_init</td>\n",
       "      <td>35</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.124017</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>imdb</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy_init_temp</td>\n",
       "      <td>50</td>\n",
       "      <td>0.153543</td>\n",
       "      <td>0.122420</td>\n",
       "      <td>1.173469</td>\n",
       "      <td>2.929293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>imdb</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>0.124190</td>\n",
       "      <td>0.124204</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>imdb</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy_init</td>\n",
       "      <td>27</td>\n",
       "      <td>0.123634</td>\n",
       "      <td>0.123645</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>imdb</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy_init_temp</td>\n",
       "      <td>17</td>\n",
       "      <td>0.136334</td>\n",
       "      <td>0.125467</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>imdb</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>0.124190</td>\n",
       "      <td>0.124157</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>imdb</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy_init</td>\n",
       "      <td>27</td>\n",
       "      <td>0.123634</td>\n",
       "      <td>0.123890</td>\n",
       "      <td>1.234694</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>imdb</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy_init_temp</td>\n",
       "      <td>50</td>\n",
       "      <td>0.154138</td>\n",
       "      <td>0.122453</td>\n",
       "      <td>1.397959</td>\n",
       "      <td>2.525253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       method     ensemble_type  ensemble_size  non_calibrated_nll  \\\n",
       "0     imdb  convex_comb            greedy             50            0.124141   \n",
       "1     imdb  convex_comb       greedy_init             35            0.124000   \n",
       "2     imdb  convex_comb  greedy_init_temp             14            0.135776   \n",
       "3     imdb  pure_logits            greedy             50            0.124141   \n",
       "4     imdb  pure_logits       greedy_init             35            0.124000   \n",
       "5     imdb  pure_logits  greedy_init_temp             50            0.153543   \n",
       "6     imdb  convex_comb            greedy             50            0.124190   \n",
       "7     imdb  convex_comb       greedy_init             27            0.123634   \n",
       "8     imdb  convex_comb  greedy_init_temp             17            0.136334   \n",
       "9     imdb  pure_logits            greedy             50            0.124190   \n",
       "10    imdb  pure_logits       greedy_init             27            0.123634   \n",
       "11    imdb  pure_logits  greedy_init_temp             50            0.154138   \n",
       "\n",
       "    calibrated_nll        c1        c2  epi_scalar  \n",
       "0         0.124230  0.969388  0.030303           1  \n",
       "1         0.124087  0.969388  0.060606           1  \n",
       "2         0.125154  1.500000  0.151515           1  \n",
       "3         0.124155  0.969388  1.010101           1  \n",
       "4         0.124017  0.969388  1.010101           1  \n",
       "5         0.122420  1.173469  2.929293           1  \n",
       "6         0.124204  0.989796  0.030303           1  \n",
       "7         0.123645  0.989796  0.060606           1  \n",
       "8         0.125467  1.500000  0.090909           1  \n",
       "9         0.124157  0.989796  1.010101           1  \n",
       "10        0.123890  1.234694  0.909091           1  \n",
       "11        0.122453  1.397959  2.525253           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_new_split(val_probs, val_labels, test_probs, test_labels, seed):\n",
    "    \"\"\"\n",
    "    Creates a new validation/test split by randomly shuffling the union of the default splits.\n",
    "    \n",
    "    Args:\n",
    "        shapes: [num_models, num_samples, num_classes]\n",
    "    Outputs:\n",
    "        shapes: [num_models, num_samples, num_classes]\n",
    "    \"\"\"\n",
    "    # Combine along the sample dimension (assumed to be 0)\n",
    "    combined_probs = torch.cat([val_probs, test_probs], dim=1)\n",
    "    combined_labels = torch.cat([val_labels, test_labels], dim=0)\n",
    "    total = combined_labels.shape[0]\n",
    "    val_count = val_labels.shape[0]\n",
    "    \n",
    "    # Create a permutation using numpy's random generator with the given seed.\n",
    "    rng = np.random.default_rng(seed)\n",
    "    permuted_indices = rng.permutation(total)\n",
    "    \n",
    "    # Compute the new split sizes\n",
    "    new_val_indices = permuted_indices[:val_count]\n",
    "    new_test_indices = permuted_indices[val_count:]\n",
    "    \n",
    "    new_val_member_probs = combined_probs[:,new_val_indices,:]\n",
    "    new_val_labels = combined_labels[new_val_indices]\n",
    "    new_test_member_probs = combined_probs[:,new_test_indices,:]\n",
    "    new_test_labels = combined_labels[new_test_indices]\n",
    "    \n",
    "    return new_val_member_probs, new_val_labels, new_test_member_probs, new_test_labels\n",
    "\n",
    "\n",
    "# Parameters for experiment\n",
    "num_datasets = 2\n",
    "datasets = dataset_names[:1]\n",
    "\n",
    "def retrieve_data(dataset_name, splits):\n",
    "    \"\"\"\n",
    "       hp_candidates, indices, predictions, targets \n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for split in splits:\n",
    "        metadataset.set_state(dataset_name=dataset_name,\n",
    "                        split=split)\n",
    "        hp_candidates, indices = metadataset._get_hp_candidates_and_indices()\n",
    "        predictions = metadataset.get_predictions(indices)\n",
    "        targets = metadataset.get_targets()\n",
    "        results[split] = (hp_candidates, indices, predictions, targets)\n",
    "    return results\n",
    "\n",
    "splits = [\"valid\", \"test\"]\n",
    "\n",
    "# used to evaluate non calibrated ensembles\n",
    "def compute_ensemble_nll(member_probs, labels, eps=1e-12):\n",
    "    ensemble_probs = member_probs.mean(dim=0)  # [num_samples, num_classes]\n",
    "    nll = -torch.gather(torch.log(ensemble_probs + eps), 1, labels.unsqueeze(1)).squeeze(1)\n",
    "    return nll.mean().item()\n",
    "\n",
    "\n",
    "# ------------- START EXPERIMENTS -----------------\n",
    "\n",
    "experimental_results = []\n",
    "\n",
    "#Loop over the datasets\n",
    "for name in datasets:\n",
    "    print(\"Processing dataset:\", name)\n",
    "    results = retrieve_data(name, splits)\n",
    "    default_val_member_probs = results['valid'][2]\n",
    "    default_val_labels = results['valid'][3]\n",
    "    default_test_member_probs = results['test'][2]\n",
    "    default_test_labels = results['test'][3]\n",
    "\n",
    "    for split in range(num_datasets):\n",
    "        if split == 0:\n",
    "            # Use the original split\n",
    "            val_member_probs = default_val_member_probs\n",
    "            val_labels = default_val_labels\n",
    "            test_member_probs = default_test_member_probs\n",
    "            test_labels = default_test_labels\n",
    "        else:\n",
    "            val_member_probs, val_labels, test_member_probs, test_labels = create_new_split(val_member_probs, val_labels, \n",
    "                                                                                            test_member_probs, test_labels,\n",
    "                                                                                             seed=split)\n",
    "        for method in [\"convex_comb\", \"pure_logits\"]:\n",
    "            calibrator = PrecomputedCalibrator(adjusting_alpha_method=method, \n",
    "                                           clamping_alphas=False, \n",
    "                                           logits_based_adjustments=True)\n",
    "            # --- Ensemble Selection Methods ---\n",
    "            greedy_indices, _ = calibrator.greedy_ensemble(member_probs=val_member_probs, \n",
    "                                                       labels=val_labels, m=50, no_resample=False)\n",
    "            #NOTE no longer init_N, also just one retured value\n",
    "            greedy_init_indices = calibrator.greedy_ensemble_with_initial(member_probs=val_member_probs, \n",
    "                                                                         labels=val_labels, m=50, no_resample=False, \n",
    "                                                                         tolerance=3, eps=1e-12)\n",
    "            \n",
    "            if method == 'convex_comb':\n",
    "                c2_vals = np.linspace(0, 3, 100)\n",
    "            elif method == 'pure_logits':\n",
    "                c2_vals = np.linspace(0, 10, 100)\n",
    "            temps = np.linspace(0.5, 2, 50)\n",
    "            epi_scalar_vals = np.array([1])\n",
    "\n",
    "            greedy_init_temp_indices, _ = calibrator.greedy_ensemble_with_initial_and_temp(member_probs=val_member_probs, \n",
    "                                                    labels=val_labels, m=50, init_N=5, no_resample=False, tolerance=3, eps=1e-12,\n",
    "                                                    c1_vals=temps, c2_vals=c2_vals, epi_scalar_vals=epi_scalar_vals)\n",
    "\n",
    "            # Create a dictionary for the three ensemble selection methods.\n",
    "            ensemble_methods = {\"greedy\": greedy_indices,\n",
    "                                \"greedy_init\": greedy_init_indices,\n",
    "                                \"greedy_init_temp\": greedy_init_temp_indices}\n",
    "\n",
    "            for ens_method, indices in ensemble_methods.items():\n",
    "                # Update validation and test ensemble probabilities based on the selected indices\n",
    "                val_probs_ens = val_member_probs[indices]\n",
    "                test_probs_ens = test_member_probs[indices]\n",
    "\n",
    "                # Grid search calibration using the validation ensemble probabilities.\n",
    "                _, best_params = calibrator.grid_search_c1_c2_precomputed(val_probs_ens, val_labels, temps, c2_vals, \n",
    "                                                                          epi_scalar_vals)\n",
    "                c1_prim = best_params['c1']\n",
    "                c2_prim = best_params['c2']\n",
    "                epi_scalar_prim = best_params['epi_scalar']\n",
    "\n",
    "                # Apply calibration on the test ensemble\n",
    "                calibrator_results = calibrator.predict(test_probs_ens, c1_prim, c2_prim, epi_scalar_prim, test_labels)\n",
    "                # Extract calibrated NLL (ensure a scalar by taking the mean over samples)\n",
    "                calibrated_nll = calibrator_results['nll'].mean()\n",
    "                # Evaluate baseline (non-calibrated) ensemble NLL on the test set\n",
    "                non_calibrated_nll = compute_ensemble_nll(test_probs_ens, test_labels)\n",
    "\n",
    "                # Store experimental results for this ensemble type\n",
    "                experimental_results.append({'dataset': name,\n",
    "                                             'Split': split,\n",
    "                                             'method': method,\n",
    "                                             'ensemble_type': ens_method,\n",
    "                                             'ensemble_size': len(indices),\n",
    "                                             'non_calibrated_nll': non_calibrated_nll,\n",
    "                                             'calibrated_nll': calibrated_nll,\n",
    "                                             'c1': c1_prim,\n",
    "                                             'c2': c2_prim,\n",
    "                                             'epi_scalar': epi_scalar_prim\n",
    "                                             })\n",
    "\n",
    "df_results = pd.DataFrame(experimental_results)\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: imdb\n",
      "Ensemble [124, 109, 99, 94, 114, 118, 87, 113, 43, 83, 112, 84, 118, 82, 117, 93, 87, 84, 108, 54, 118, 7, 98, 113, 84, 87, 38, 118, 93, 108]: NLL = 0.12387\n",
      "Initial candidate pool (top 5 models): [94, 99, 84, 93, 98]\n",
      "Completed calibration for initial candidate pool ([94, 99, 84, 93, 98]), with an NLL of:  0.14777784049510956\n",
      "Stopping early.\n",
      "Ensemble [94, 99, 84, 93, 98, 109, 118, 87, 43, 113, 112, 118, 82, 117]: NLL = 0.12526\n",
      "Ensemble [124, 109, 99, 94, 114, 118, 87, 113, 43, 83, 112, 84, 118, 82, 117, 93, 87, 84, 108, 54, 118, 7, 98, 113, 84, 87, 38, 118, 93, 108]: NLL = 0.12387\n",
      "Initial candidate pool (top 5 models): [94, 99, 84, 93, 98]\n",
      "Completed calibration for initial candidate pool ([94, 99, 84, 93, 98]), with an NLL of:  0.14334142208099365\n",
      "Ensemble [94, 99, 84, 93, 98, 118, 108, 123, 48, 113, 108, 88, 118, 87, 103, 108, 97, 123, 88, 73, 118, 79, 113, 108, 87, 112, 123, 88, 102, 79, 108, 97, 118, 43, 113, 108, 123, 79, 82, 88, 103, 87, 112, 108, 78, 123, 97, 118, 79, 73]: NLL = 0.12540\n",
      "Processing dataset: mteb/tweet_sentiment_extraction\n",
      "Ensemble [54, 64, 59, 49, 69, 57, 33, 77, 73, 28, 78, 57, 23, 91, 73, 97, 43, 57, 63, 48, 93, 86, 73, 13, 57, 33, 24, 78, 53, 77, 28, 73, 57, 96, 83, 8, 97, 38, 73, 57, 91, 68, 33, 82, 44, 78, 28, 73, 77, 43]: NLL = 0.49499\n",
      "Initial candidate pool (top 5 models): [73, 68, 54, 63, 57]\n",
      "Completed calibration for initial candidate pool ([73, 68, 54, 63, 57]), with an NLL of:  0.5321660041809082\n",
      "Stopping early.\n",
      "Ensemble [73, 68, 54, 63, 57, 77, 33, 91, 28, 78, 23, 97, 43, 64, 93, 48, 53]: NLL = 0.49755\n",
      "Ensemble [54, 64, 59, 49, 69, 57, 33, 77, 73, 28, 78, 57, 23, 91, 73, 97, 43, 57, 63, 48, 93, 86, 73, 13, 57, 33, 24, 78, 53, 77, 28, 73, 57, 96, 83, 8, 97, 38, 73, 57, 91, 68, 33, 82, 44, 78, 28, 73, 77, 43]: NLL = 0.49499\n",
      "Initial candidate pool (top 5 models): [73, 68, 54, 63, 57]\n",
      "Completed calibration for initial candidate pool ([73, 68, 54, 63, 57]), with an NLL of:  0.5320340991020203\n",
      "Stopping early.\n",
      "Ensemble [73, 68, 54, 63, 57, 77, 33, 28, 78, 13, 97, 43, 91, 93, 48, 53]: NLL = 0.49722\n",
      "Processing dataset: ag_news\n",
      "Ensemble [99, 98, 93, 94, 88, 16, 73, 113, 112, 28, 2, 108, 97, 83, 118, 38, 7, 63, 77, 68, 103, 83, 17, 113, 101, 33, 22, 83, 73, 113, 28, 97, 108, 83, 114, 58, 2, 78, 118, 92, 53, 83, 1, 28, 113, 7, 73, 83, 44, 108]: NLL = 0.18950\n",
      "Initial candidate pool (top 5 models): [98, 93, 99, 88, 94]\n",
      "Completed calibration for initial candidate pool ([98, 93, 99, 88, 94]), with an NLL of:  0.20316889882087708\n",
      "Stopping early.\n",
      "Ensemble [98, 93, 99, 88, 94, 38, 113, 7, 73, 21, 28, 108, 97, 83, 118, 2, 63]: NLL = 0.18448\n",
      "Ensemble [99, 98, 93, 94, 88, 16, 73, 113, 112, 28, 2, 108, 97, 83, 118, 38, 7, 63, 77, 68, 103, 83, 17, 113, 101, 33, 22, 83, 73, 113, 28, 97, 108, 83, 114, 58, 2, 78, 118, 92, 53, 83, 1, 28, 113, 7, 73, 83, 44, 108]: NLL = 0.18950\n",
      "Initial candidate pool (top 5 models): [98, 93, 99, 88, 94]\n",
      "Completed calibration for initial candidate pool ([98, 93, 99, 88, 94]), with an NLL of:  0.20154666900634766\n",
      "Stopping early.\n",
      "Ensemble [98, 93, 99, 88, 94, 113, 38, 97, 108, 73, 77, 28, 118, 83, 2, 63, 113, 83, 68, 92, 103, 78, 4, 38, 113, 83, 108, 7, 28, 97, 73, 83, 113, 21, 77, 108, 78, 17, 58, 118, 83, 33]: NLL = 0.18123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>ensemble_type</th>\n",
       "      <th>ensemble_size</th>\n",
       "      <th>non_calibrated_nll</th>\n",
       "      <th>calibrated_nll</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>epi_scalar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imdb</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>0.124141</td>\n",
       "      <td>0.124230</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imdb</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy_init</td>\n",
       "      <td>50</td>\n",
       "      <td>0.124880</td>\n",
       "      <td>0.124498</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imdb</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy_init_temp</td>\n",
       "      <td>50</td>\n",
       "      <td>0.135776</td>\n",
       "      <td>0.125154</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imdb</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>0.124141</td>\n",
       "      <td>0.124155</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imdb</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy_init</td>\n",
       "      <td>50</td>\n",
       "      <td>0.124880</td>\n",
       "      <td>0.124374</td>\n",
       "      <td>1.091837</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>imdb</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy_init_temp</td>\n",
       "      <td>50</td>\n",
       "      <td>0.153543</td>\n",
       "      <td>0.122420</td>\n",
       "      <td>1.173469</td>\n",
       "      <td>2.929293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mteb/tweet_sentiment_extraction</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>0.507702</td>\n",
       "      <td>0.507260</td>\n",
       "      <td>1.051020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mteb/tweet_sentiment_extraction</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy_init</td>\n",
       "      <td>50</td>\n",
       "      <td>0.508739</td>\n",
       "      <td>0.507940</td>\n",
       "      <td>1.091837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mteb/tweet_sentiment_extraction</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy_init_temp</td>\n",
       "      <td>50</td>\n",
       "      <td>0.523816</td>\n",
       "      <td>0.508146</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mteb/tweet_sentiment_extraction</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>0.507702</td>\n",
       "      <td>0.506611</td>\n",
       "      <td>1.193878</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mteb/tweet_sentiment_extraction</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy_init</td>\n",
       "      <td>50</td>\n",
       "      <td>0.508739</td>\n",
       "      <td>0.508033</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mteb/tweet_sentiment_extraction</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy_init_temp</td>\n",
       "      <td>50</td>\n",
       "      <td>0.531979</td>\n",
       "      <td>0.506615</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.212121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ag_news</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>0.197836</td>\n",
       "      <td>0.193725</td>\n",
       "      <td>1.377551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ag_news</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy_init</td>\n",
       "      <td>50</td>\n",
       "      <td>0.200381</td>\n",
       "      <td>0.196027</td>\n",
       "      <td>1.397959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ag_news</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>greedy_init_temp</td>\n",
       "      <td>50</td>\n",
       "      <td>0.225418</td>\n",
       "      <td>0.195852</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ag_news</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>0.197836</td>\n",
       "      <td>0.191803</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ag_news</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy_init</td>\n",
       "      <td>50</td>\n",
       "      <td>0.200381</td>\n",
       "      <td>0.194248</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ag_news</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>greedy_init_temp</td>\n",
       "      <td>50</td>\n",
       "      <td>0.226644</td>\n",
       "      <td>0.191699</td>\n",
       "      <td>1.438776</td>\n",
       "      <td>1.616162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            dataset       method     ensemble_type  \\\n",
       "0                              imdb  convex_comb            greedy   \n",
       "1                              imdb  convex_comb       greedy_init   \n",
       "2                              imdb  convex_comb  greedy_init_temp   \n",
       "3                              imdb  pure_logits            greedy   \n",
       "4                              imdb  pure_logits       greedy_init   \n",
       "5                              imdb  pure_logits  greedy_init_temp   \n",
       "6   mteb/tweet_sentiment_extraction  convex_comb            greedy   \n",
       "7   mteb/tweet_sentiment_extraction  convex_comb       greedy_init   \n",
       "8   mteb/tweet_sentiment_extraction  convex_comb  greedy_init_temp   \n",
       "9   mteb/tweet_sentiment_extraction  pure_logits            greedy   \n",
       "10  mteb/tweet_sentiment_extraction  pure_logits       greedy_init   \n",
       "11  mteb/tweet_sentiment_extraction  pure_logits  greedy_init_temp   \n",
       "12                          ag_news  convex_comb            greedy   \n",
       "13                          ag_news  convex_comb       greedy_init   \n",
       "14                          ag_news  convex_comb  greedy_init_temp   \n",
       "15                          ag_news  pure_logits            greedy   \n",
       "16                          ag_news  pure_logits       greedy_init   \n",
       "17                          ag_news  pure_logits  greedy_init_temp   \n",
       "\n",
       "    ensemble_size  non_calibrated_nll  calibrated_nll        c1        c2  \\\n",
       "0              50            0.124141        0.124230  0.969388  0.030303   \n",
       "1              50            0.124880        0.124498  1.071429  0.060606   \n",
       "2              50            0.135776        0.125154  1.500000  0.151515   \n",
       "3              50            0.124141        0.124155  0.969388  1.010101   \n",
       "4              50            0.124880        0.124374  1.091837  1.010101   \n",
       "5              50            0.153543        0.122420  1.173469  2.929293   \n",
       "6              50            0.507702        0.507260  1.051020  0.000000   \n",
       "7              50            0.508739        0.507940  1.091837  0.000000   \n",
       "8              50            0.523816        0.508146  1.500000  0.000000   \n",
       "9              50            0.507702        0.506611  1.193878  0.909091   \n",
       "10             50            0.508739        0.508033  1.071429  1.010101   \n",
       "11             50            0.531979        0.506615  1.500000  1.212121   \n",
       "12             50            0.197836        0.193725  1.377551  0.000000   \n",
       "13             50            0.200381        0.196027  1.397959  0.000000   \n",
       "14             50            0.225418        0.195852  1.500000  0.000000   \n",
       "15             50            0.197836        0.191803  1.500000  0.808081   \n",
       "16             50            0.200381        0.194248  1.500000  0.808081   \n",
       "17             50            0.226644        0.191699  1.438776  1.616162   \n",
       "\n",
       "    epi_scalar  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "5            1  \n",
       "6            1  \n",
       "7            1  \n",
       "8            1  \n",
       "9            1  \n",
       "10           1  \n",
       "11           1  \n",
       "12           1  \n",
       "13           1  \n",
       "14           1  \n",
       "15           1  \n",
       "16           1  \n",
       "17           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = dataset_names[:3]\n",
    "\n",
    "experimental_results = []\n",
    "\n",
    "for name in datasets:\n",
    "    print(\"Processing dataset:\", name)\n",
    "    results = retrieve_data(name, splits)\n",
    "    val_member_probs = results['valid'][2]\n",
    "    val_labels = results['valid'][3]\n",
    "    test_member_probs = results['test'][2]\n",
    "    test_labels = results['test'][3]\n",
    "\n",
    "    for method in [\"convex_comb\", \"pure_logits\"]:\n",
    "        calibrator = PrecomputedCalibrator(adjusting_alpha_method=method, \n",
    "                                           clamping_alphas=False, \n",
    "                                           logits_based_adjustments=True)\n",
    "        # --- Ensemble Selection Methods ---\n",
    "        # 1. Greedy ensemble (with resampling)\n",
    "        greedy_indices, _ = calibrator.greedy_ensemble(member_probs=val_member_probs, \n",
    "                                                       labels=val_labels, m=50, no_resample=False)\n",
    "        # 2. Greedy ensemble with an initial candidate pool\n",
    "        greedy_init_indices = calibrator.greedy_ensemble_with_initial(member_probs=val_member_probs, \n",
    "                                                                         labels=val_labels, m=50,\n",
    "                                                                         no_resample=False, \n",
    "                                                                         tolerance=3, eps=1e-12)\n",
    "        # 3. Greedy ensemble with initial + temperature scaling calibration\n",
    "        if method == 'convex_comb':\n",
    "            c2_vals = np.linspace(0, 3, 100)\n",
    "        elif method == 'pure_logits':\n",
    "            c2_vals = np.linspace(0, 10, 100)\n",
    "        temps = np.linspace(0.5, 1.5, 50)\n",
    "        epi_scalar_vals = np.array([1])\n",
    "        greedy_init_temp_indices, _ = calibrator.greedy_ensemble_with_initial_and_temp(member_probs=val_member_probs, \n",
    "                                                    labels=val_labels, m=50, init_N=5, no_resample=False, tolerance=3, eps=1e-12,\n",
    "                                                    c1_vals=temps, c2_vals=c2_vals, epi_scalar_vals=epi_scalar_vals)\n",
    "\n",
    "        # Create a dictionary for the three ensemble selection methods.\n",
    "        ensemble_methods = {\n",
    "            \"greedy\": greedy_indices,\n",
    "            \"greedy_init\": greedy_init_indices,\n",
    "            \"greedy_init_temp\": greedy_init_temp_indices\n",
    "        }\n",
    "\n",
    "        # Loop over each ensemble type\n",
    "        for ens_method, indices in ensemble_methods.items():\n",
    "            # Update validation and test ensemble probabilities based on the selected indices\n",
    "            val_probs_ens = val_member_probs[indices]\n",
    "            test_probs_ens = test_member_probs[indices]\n",
    "\n",
    "            # Grid search calibration using the validation ensemble probabilities.\n",
    "            _, best_params = calibrator.grid_search_c1_c2_precomputed(\n",
    "                val_probs_ens, val_labels, temps, c2_vals, epi_scalar_vals)\n",
    "            c1_prim = best_params['c1']\n",
    "            c2_prim = best_params['c2']\n",
    "            epi_scalar_prim = best_params['epi_scalar']\n",
    "\n",
    "            # Apply calibration on the test ensemble\n",
    "            calibrator_results = calibrator.predict(test_probs_ens, c1_prim, c2_prim, epi_scalar_prim, test_labels)\n",
    "            # Extract calibrated NLL (ensure a scalar by taking the mean over samples)\n",
    "            calibrated_nll = calibrator_results['nll'].mean()\n",
    "            # Evaluate baseline (non-calibrated) ensemble NLL on the test set\n",
    "            non_calibrated_nll = compute_ensemble_nll(test_probs_ens, test_labels)\n",
    "\n",
    "            # Store experimental results for this ensemble type\n",
    "            experimental_results.append({\n",
    "                'dataset': name,\n",
    "                'method': method,\n",
    "                'ensemble_type': ens_method,\n",
    "                'ensemble_size': len(indices),\n",
    "                'non_calibrated_nll': non_calibrated_nll,\n",
    "                'calibrated_nll': calibrated_nll,\n",
    "                'c1': c1_prim,\n",
    "                'c2': c2_prim,\n",
    "                'epi_scalar': epi_scalar_prim\n",
    "            })\n",
    "\n",
    "df_results = pd.DataFrame(experimental_results)\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 20, 10]),\n",
       " torch.Size([20]),\n",
       " torch.Size([5, 100, 10]),\n",
       " torch.Size([100]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_new_split(val_probs, val_labels, test_probs, test_labels, seed):\n",
    "    \"\"\"\n",
    "    Creates a new validation/test split by randomly shuffling the union of the default splits.\n",
    "    \n",
    "    Args:\n",
    "        shapes: [num_models, num_samples, num_classes]\n",
    "    Outputs:\n",
    "        shapes: [num_models, num_samples, num_classes]\n",
    "    \"\"\"\n",
    "    # Combine along the sample dimension (assumed to be 0)\n",
    "    combined_probs = torch.cat([val_probs, test_probs], dim=1)\n",
    "    combined_labels = torch.cat([val_labels, test_labels], dim=0)\n",
    "    total = combined_labels.shape[0]\n",
    "    val_count = val_labels.shape[0]\n",
    "    \n",
    "    # Create a permutation using numpy's random generator with the given seed.\n",
    "    rng = np.random.default_rng(seed)\n",
    "    permuted_indices = rng.permutation(total)\n",
    "    \n",
    "    # Compute the new split sizes\n",
    "    new_val_indices = permuted_indices[:val_count]\n",
    "    new_test_indices = permuted_indices[val_count:]\n",
    "    \n",
    "    new_val_member_probs = combined_probs[:,new_val_indices,:]\n",
    "    new_val_labels = combined_labels[new_val_indices]\n",
    "    new_test_member_probs = combined_probs[:,new_test_indices,:]\n",
    "    new_test_labels = combined_labels[new_test_indices]\n",
    "    \n",
    "    return new_val_member_probs, new_val_labels, new_test_member_probs, new_test_labels\n",
    "\n",
    "\n",
    "#test delete later - shape [num_models, num_samples, num_classes]\n",
    "test_tensor = torch.randn(5, 100, 10)\n",
    "test_labels = torch.randint(0, 10, (100,))\n",
    "val_tensor = torch.randn(5, 20, 10)\n",
    "val_labels = torch.randint(0, 10, (20,))\n",
    "\n",
    "#example usage\n",
    "new_val_probs, new_val_labels, new_test_probs, new_test_labels = create_new_split(val_tensor, val_labels, test_tensor, test_labels, seed=42)\n",
    "new_val_probs.shape, new_val_labels.shape, new_test_probs.shape, new_test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple pipeline (old) on mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----------------------\n",
      "Dataset: imdb\n",
      "\n",
      " ----------------------\n",
      "Dataset: mteb/tweet_sentiment_extraction\n",
      "\n",
      " ----------------------\n",
      "Dataset: ag_news\n",
      "\n",
      " ----------------------\n",
      "Dataset: dbpedia_14\n",
      "\n",
      " ----------------------\n",
      "Dataset: stanfordnlp/sst2\n",
      "\n",
      " ----------------------\n",
      "Dataset: SetFit/mnli\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Calibration method</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>epi_scalar</th>\n",
       "      <th>nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imdb</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imdb</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imdb</td>\n",
       "      <td>convex_comb_no_exp</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imdb</td>\n",
       "      <td>convex_comb_global</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mteb/tweet_sentiment_extraction</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mteb/tweet_sentiment_extraction</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mteb/tweet_sentiment_extraction</td>\n",
       "      <td>convex_comb_no_exp</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mteb/tweet_sentiment_extraction</td>\n",
       "      <td>convex_comb_global</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ag_news</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ag_news</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ag_news</td>\n",
       "      <td>convex_comb_no_exp</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ag_news</td>\n",
       "      <td>convex_comb_global</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dbpedia_14</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dbpedia_14</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dbpedia_14</td>\n",
       "      <td>convex_comb_no_exp</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dbpedia_14</td>\n",
       "      <td>convex_comb_global</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stanfordnlp/sst2</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>1.155556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stanfordnlp/sst2</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>stanfordnlp/sst2</td>\n",
       "      <td>convex_comb_no_exp</td>\n",
       "      <td>1.155556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>stanfordnlp/sst2</td>\n",
       "      <td>convex_comb_global</td>\n",
       "      <td>1.155556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SetFit/mnli</td>\n",
       "      <td>convex_comb</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SetFit/mnli</td>\n",
       "      <td>pure_logits</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.353807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SetFit/mnli</td>\n",
       "      <td>convex_comb_no_exp</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SetFit/mnli</td>\n",
       "      <td>convex_comb_global</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            dataset  Calibration method        C1        C2  \\\n",
       "0                              imdb         convex_comb  0.977778  0.030303   \n",
       "1                              imdb         pure_logits  0.977778  1.010101   \n",
       "2                              imdb  convex_comb_no_exp  0.977778  0.000000   \n",
       "3                              imdb  convex_comb_global  0.977778  0.101010   \n",
       "4   mteb/tweet_sentiment_extraction         convex_comb  1.066667  0.000000   \n",
       "5   mteb/tweet_sentiment_extraction         pure_logits  1.200000  0.909091   \n",
       "6   mteb/tweet_sentiment_extraction  convex_comb_no_exp  1.066667  0.000000   \n",
       "7   mteb/tweet_sentiment_extraction  convex_comb_global  1.066667  0.000000   \n",
       "8                           ag_news         convex_comb  1.200000  0.000000   \n",
       "9                           ag_news         pure_logits  1.200000  0.909091   \n",
       "10                          ag_news  convex_comb_no_exp  1.200000  0.000000   \n",
       "11                          ag_news  convex_comb_global  1.200000  0.000000   \n",
       "12                       dbpedia_14         convex_comb  1.200000  0.000000   \n",
       "13                       dbpedia_14         pure_logits  1.200000  1.010101   \n",
       "14                       dbpedia_14  convex_comb_no_exp  1.200000  0.000000   \n",
       "15                       dbpedia_14  convex_comb_global  1.200000  0.010101   \n",
       "16                 stanfordnlp/sst2         convex_comb  1.155556  0.000000   \n",
       "17                 stanfordnlp/sst2         pure_logits  1.200000  0.909091   \n",
       "18                 stanfordnlp/sst2  convex_comb_no_exp  1.155556  0.000000   \n",
       "19                 stanfordnlp/sst2  convex_comb_global  1.155556  0.000000   \n",
       "20                      SetFit/mnli         convex_comb  1.200000  0.000000   \n",
       "21                      SetFit/mnli         pure_logits  1.200000  0.909091   \n",
       "22                      SetFit/mnli  convex_comb_no_exp  1.200000  0.000000   \n",
       "23                      SetFit/mnli  convex_comb_global  1.200000  0.000000   \n",
       "\n",
       "    epi_scalar       nll  \n",
       "0            1  0.124203  \n",
       "1            1  0.124134  \n",
       "2            1  0.124203  \n",
       "3            1  0.124203  \n",
       "4            1  0.507160  \n",
       "5            1  0.506576  \n",
       "6            1  0.507160  \n",
       "7            1  0.507160  \n",
       "8            1  0.195051  \n",
       "9            1  0.195210  \n",
       "10           1  0.195051  \n",
       "11           1  0.195051  \n",
       "12           1  0.034172  \n",
       "13           1  0.034179  \n",
       "14           1  0.034172  \n",
       "15           1  0.034172  \n",
       "16           1  0.135794  \n",
       "17           1  0.135866  \n",
       "18           1  0.135794  \n",
       "19           1  0.135794  \n",
       "20           1  0.354990  \n",
       "21           1  0.353807  \n",
       "22           1  0.354990  \n",
       "23           1  0.354990  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No actual need for seeds\n",
    "\n",
    "data_dir = \"../data\"\n",
    "data_version = \"mini\"                                   #10% of total with 20% val split\n",
    "#data_version = \"extended\"                              # NOTE not yet downloaded\n",
    "metadataset = FTCMetadataset(data_dir=str(data_dir), \n",
    "                             metric_name=\"error\",\n",
    "                             data_version=data_version)\n",
    "dataset_names = metadataset.get_dataset_names()\n",
    "\n",
    "splits = [\"valid\", \"test\"]      # based of github\n",
    "\n",
    "calibration_results = []\n",
    "\n",
    "for name in dataset_names:\n",
    "    print('\\n ----------------------')\n",
    "    print(f'Dataset: {name}')\n",
    "    results = retrieve_data(name, splits)\n",
    "    val_member_probs = results['valid'][2]\n",
    "    val_labels = results['valid'][3]\n",
    "    test_member_probs = results['test'][2]\n",
    "    test_labels = results['test'][3]\n",
    "\n",
    "    for method  in [\"convex_comb\", \"pure_logits\", \"convex_comb_no_exp\", \"convex_comb_global\"]:\n",
    "        #print(f'Method: {method}')\n",
    "        calibrator = PrecomputedCalibrator(adjusting_alpha_method=method, clamping_alphas=False, logits_based_adjustments=True)\n",
    "        ensemble_indices, _ = calibrator.greedy_select_ensemble(member_probs = val_member_probs, labels= val_labels, m = 50, \n",
    "                                                        no_resample=False) \n",
    "        # only take the probs of the selected ensemble\n",
    "        val_member_probs = val_member_probs[ensemble_indices]\n",
    "        test_member_probs = test_member_probs[ensemble_indices]\n",
    "\n",
    "        if method == 'convex_comb':\n",
    "            c2_vals = np.linspace(0, 3, 100)\n",
    "        elif method == 'pure_logits':\n",
    "            c2_vals = np.linspace(0, 10, 100)\n",
    "        elif method == 'convex_comb_no_exp':\n",
    "            c2_vals = np.linspace(0, 10, 100)\n",
    "        elif method == 'convex_comb_global':\n",
    "            c2_vals = np.linspace(0, 1, 100)\n",
    "\n",
    "        c1_vals = np.linspace(0.8, 1.2, 10)\n",
    "        epi_scalar_vals = np.array([1])\n",
    "\n",
    "        _, best_params = calibrator.grid_search_c1_c2_precomputed(val_member_probs, val_labels,\n",
    "                                                       c1_vals, c2_vals, epi_scalar_vals)\n",
    "\n",
    "        c1_prim = best_params['c1']\n",
    "        c2_prim = best_params['c2']\n",
    "        epi_scalar_prim = best_params['epi_scalar']\n",
    "\n",
    "        calibrator_results = calibrator.predict(test_member_probs, c1_prim, c2_prim, epi_scalar_prim, test_labels)\n",
    "        calibration_results.append({'dataset': name, \n",
    "                                    'Calibration method': method,\n",
    "                                    'C1': c1_prim,\n",
    "                                    'C2': c2_prim,\n",
    "                                    'epi_scalar': epi_scalar_prim,\n",
    "                                    'nll': calibrator_results['nll'].mean()})\n",
    "\n",
    "        #print(\"Calibrated test nll: \", calibrator_results['nll'].mean())\n",
    "        #print(\"Non claibrated test nll :\", compute_ensemble_nll(test_member_probs, test_labels))\n",
    "\n",
    "calibration_results = pd.DataFrame(calibration_results)\n",
    "calibration_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}